%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
\cleardoubleoddpage%  Make sure to start each chapter on a new odd page
\chapter{Literature Review}

\section{Current State of Respiratory Sound Analysis}
Lung auscultation is the standard method of diagnosing respiratory disease by listening to the patient's lungs through the chest. However, this approach, which relies on manual assessment by healthcare professionals, has several limitations. Its effectiveness depends on the physician's skill, experience and auditory sensitivity, leading to potential inaccuracies in diagnosis~\cite{palaniappan2013computer}. In addition, manual auscultation is typically limited to clinical settings, missing critical auditory cues that may occur outside of these settings, such as nocturnal breath sounds common in conditions such as asthma~\cite{pramono2017automatic}. \\
These limitations, combined with advances in technology, have led to the development of computerized respiratory sound analysis. In this approach, lung sounds are digitally recorded and then analyzed. Early techniques focused on the graphical representation of sound waves, allowing medical professionals to visually identify abnormalities. However, this method did not fully mitigate the risk of human error. Subsequently, statistical approaches were developed to assess the frequency of specific respiratory events based on historical data patterns. According to systematic reviews~\cite{palaniappan2013computer}, machine learning based approaches provide the most promising results, but so far were limited by the lack of sufficiently large data sets.

\subsection{The ICBHI Challenge 2017}
During the 2017 Annual International Conference on Biomedical and Health Informatics, a central challenge was launched in response to the scarcity of comprehensive lung sound data. This challenge aimed to foster the development and evaluation of advanced algorithms for automated lung sound classification, using a novel dataset curated specifically for this purpose. Known as the Respiratory Sound Database~\cite{rocha2018alpha}, this collection stands out as one of the earliest and most comprehensive publicly available datasets in the field, comprising 6898 respiratory cycles from 126 patients. These recordings, collected by professional teams in Greece and Portugal, represent a diverse range of audio samples, capturing sounds from healthy individuals as well as patients suffering from lung diseases such as COPD, asthma, and bronchiectasis. Each breathing cycle in the database is annotated by domain experts and categorized as normal, with wheezes, with crackles, or with both wheezes and crackles. The challenge encouraged a multitude of submissions, showcasing a range of innovative machine learning approaches. Below, we compare a selection of these methods.

\subsection{Existing Approaches}
Starting with traditional artificial intelligence methods, Jakovljevi{\'c} and Lon{\v{c}}ar-Turukalo (2018) published their work based on hidden Markov models (HMM) alongside the paper introducing the Respiratory Sound Database.~\cite{jakovljevic2018hidden}. Using MFCCs as features, they employed a four-class classifier with the official 60/40 split at the recording level, using 60\% of the data for training and the remaining 40\% for evaluation. The four classes were healthy, crackles, wheezes, both crackles and wheezes. A balanced accuracy score of 0.39 was achieved, with sensitivity of 0.38 and specificity of 0.41.\\
Chambres et al. (2018) used boosted decision trees (BDT) to address the four-class classification task~\cite{chambres2018automatic}. They used the same 60/40 split and MFCCs as features. The model architecture significantly improved the balance accuracy to 0.49, with a sensitivity of 0.78 and a specificity of 0.21.\\
Shortly after, the use of neural networks gained traction. Ma et al. (2019) proposed the use of a bi-ResNet (LungBRN) architecture~\cite{wang2019bi} consisting of multiple concatenated convolutional neural network layers~\cite{ma2019lungbrn}. Using the same split as the other approaches, but using short-time Fourier transform (STFT) and wavelet analysis to extract features, they achieved an official balanced accuracy of 0.5, specificity of 0.69, and sensitivity of 0.31 for the four-class problem.\\
The Microsoft Research India team around Gairola et al. (2021) published their RepireNet~\cite{gairola2021respirenet} network and benchmarked it in a variety of data splits and in a binary and four-class classification problem. The backbone are blocks of ResNet34~\cite{he2016deep} deep convolutional neural networks (CNN). Using MelSpectrograms as features, their baseline CNN achieved 0.55 balanced accuracy on the official 60/40 split, 0.66 balanced accuracy for the four-class problem on a self-defined random 80/20 split at the breathing cycle level, and 0.72 on the same 80/20 split but treating the problem as a binary classification, which allows for an easier comparison to a anomaly detection setting.\\
\begin{table}[h!]
    \centering
    \caption{
        Performance comparisons of the showcased models 
    }
    \begin{tabularx}{\linewidth}{lXcccc}
    \toprule
    \textbf{Model}        & \textbf{Split} & \textbf{Features} & \textbf{Se} & \textbf{Sp} & \textbf{BALACC} \\
    \midrule
    HMM                   & 60/40 4 class          & MFCC              & 0.38                & 0.41                 & 0.39 \\
    BDT                   & 60/40 4 class          & MFCC              & 0.78                & 0.21                 & 0.49 \\
    LungBRN               & 60/40 4 class          & STFT + Wavelet    & 0.69                & 0.31                 & 0.5  \\
    RespireNet CNN        & 60/40 4 class          & MelSpectrogram    & 0.39                & 0.71                 & 0.55 \\
    RespireNet CNN        & 80/20 4 class  & MelSpectrogram    & 0.54                & 0.79                 & 0.66 \\
    RespireNet CNN        & 80/20 2 class  & MelSpectrogram    & 0.61                & 0.83                 & 0.72 \\
    \bottomrule
    \end{tabularx}
\end{table}

% CHECK ALL RESULTS IF THEY ARE CORRECT!
    
It is important to note that all mentioned approaches to respiratory sounds analysis rely on treating it as a supervised classification task. These methods, while effective in their context, assume the availability of extensive labeled data representing various specific respiratory conditions. In real-world scenarios, however, such comprehensive data sets are not always readily available. Furthermore, the strict categorization of respiratory sounds into predefined classes may overlook the nuanced and unpredictable nature of respiratory anomalies. Therefore, the remainder of this thesis will explore respiratory sound analysis through the lens of anomaly detection.

\section{Respiratory Sound Analysis from an Anomaly Detection Perspective}
The use of anomaly detection methods to solve sound analysis problems is not a new concept. In particular, these methods have proven their effectiveness in the field of industrial sound analysis, as demonstrated in Task 2 of the annual DCASE Challenge~\cite{dcaseDCASE2023Challenge}, where machine condition monitoring is performed by observing the sound produced by these machines. The sound emitted can be either normal or anomalous, and machine learning algorithms learn to understand the characteristics of healthy machine sounds in order to accurately predict machine failure in the case of anomalous sounds such as rattling or whirring.\\
A similar approach can be used in breathing sound analysis. The different anomalous respiratory sounds can all be grouped into a single anomaly class, and anomaly detection models can learn the constitution of healthy respiratory cycles. If a sample deviates significantly from the learned representation of a healthy sound, the system can flag it as anomalous.


\section{Variational Autoencoders}
Cozzatti et al. (2022)~\cite{cozzatti2022variational} explored the first anomaly detection approach to the respiratory sound database. In their work, MFCCs were used as features and the breathing cycles containing wheezes, crackles or both were all summarized in an anomaly class. A Variational Autoencoder (VAE) was trained using only known healthy breathing cycles.\\
Variational Autoencoders are similar to Autoencoders in that they consist of an encoder and a decoder part. The encoder of a VAE, by comparison, uses variational inference to output the parameters of a continuous and easily sampled distribution, usually the mean and standard deviation of a  Gaussian~\cite{cozzatti2022variational}. As a result, the input to the decoder is a single sample from that predicted distribution. This allows the model to provide a measure of certainty of the reconstruced data using the variability of the latent space~\cite{an2015variational}.\\

% Maybe include an illustration of VAE?

By training the VAE with normal sounds only, it learns to accurately reconstruct physiological respiratory cycles. The reconstruction error reported by the model is small in this case. When the model attempts to reconstruct a respiratory sound with pathologies, the parameters of the Gaussian will most likely not match the parameters of the learned distribution of healthy sounds, and thus the reconstruction will have a higher error. The paper then used a small subset of the original dataset, containing both healthy and unhealthy lung sounds, to determine a threshold in the reconstruction error above which all higher errors should be marked as anomalous, making the process weakly supervised. The proposed model achieved competitive results in the binary class problem, with a balanced accuracy of 0.57 for the official 60/40 split and 0.6 for a random 80/20 split.

\begin{table}[h!]
    \centering
    \caption{Performance of the proposed method}
    \begin{tabular}{cccccc}
    \toprule
    \textbf{Split} & \textbf{Se} & \textbf{Sp} & \textbf{BALACC} \\
    \midrule
    60/40 & 0.33 & 0.80 & 0.57 \\
    80/20 & 0.58 & 0.61 & 0.60 \\
    \bottomrule
    \end{tabular}
\end{table}


\section{Group Masked Autoencoders}
In \autoref{theory:made}, we have discussed how Masked Autoencoders are an alternative anomaly detection approach to generative models by evaluating probability densities. The basic concept focused on modifying an existing autoencoder structure to satisfy the autoregressive property by masking the weights of the neural network layers so that each output dimension depends only on the preceding input dimensions.\\
When dealing with representations of sound data, such as MelSpectrograms or MFCCS, the interest shifts from the autoregressive ordering of individual input dimensions to the ordering of sound frames. Here, Group Masked Autoencoders (GMADE)~\cite{Giri2020} provide a more tailored approach for audio anomaly detection tasks where temporal context is important. GMADE differs from traditional MADE in that it does not split the joint distribution into individual dimensional conditions, but rather over grouped frames. This approach is particularly relevant when dealing with sound data, where each time frame in a MelSpectrogram is considered a separate group.\\
In GMADE, the input space has the dimensionality $T\times M$, where $T$ is the number of frames concatenated in the input and $M$ is the number of Mel frequency bands. If an input sample can be thought of as $\mathbf{t}=[\mathbf{t_{i+1}}, \mathbf{t_{i+2}},... ,\mathbf{t_{i+T}}]$ with $\mathbf{t_{i}}\in \mathbb{R}^{M\times 1}$, the joint density can be decomposed as \[ p(\mathbf{t})=\sum_{i=1}^{T}p(\mathbf{t_i}|\mathbf{t}_{<i}) \] where the probability of each frame depends on all previous frames and their mel bins and no other frames~\cite{Giri2020}. To maintain the autoregressive property, the generation of the weight matrices must be slightly adapted from the MADE approach to assign labels to the neurons only from $1$ to $T-1$ to correctly zero connections between groups instead of units.\\
The paper also explored orderings other than causal, where a frame can only depend on its predecessors. Backward ordering predicts the probability density of frames given only their succeeding frames, while middle frame ordering attempts to predict the middle frame given only the frames surrounding it. Ensembles of all three approaches were also evaluated. GMADE achieved state of the art results in Task 2 of the DCASE Challenge 2020 in the machine condition monitoring task, especially for non-stationary sounds. While this is promising for respiratory sound analysis due to the non-stationary nature of lung sounds, the efficacy of GMADE in detecting anomalies in respiratory sounds is yet to be tested.

% IMPORTANT: Add a section summarizing the findings from the literature review and creating an outline of what will be done in the methodology part
% We have seen some historical background and the first couple of attempts
% Highlight the first anomaly detection approach to this
% G-MADE is left to be tried for anomaly detection in respiratory sounds

%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%